{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Variables\n",
    "vocab_size = 3000\n",
    "embedding_dim = 32\n",
    "max_length = 60\n",
    "truncation_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<OOV>\"\n",
    "training_size = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "1    15576\n",
      "Name: count, dtype: int64 labels\n",
      "0    16000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataList = []\n",
    "sentences = []\n",
    "labels = []\n",
    "# Stopwords should be removed or excluded from the given text so that more \n",
    "# focus can be given to those words which define the meaning of the text.\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def loadDataset(filename):\n",
    "  d=[]\n",
    "  with open(filename, 'r') as f:\n",
    "      datastore = json.load(f)\n",
    "  for item in datastore:\n",
    "    sentence = item['data']\n",
    "    label = item['is_sensitive']\n",
    "    for word in stopwords: #Remove stop words in sentence\n",
    "      token = \" \" + word + \" \"\n",
    "      sentence = sentence.replace(token, \" \")\n",
    "    d.append([sentence,label])\n",
    "  return d\n",
    "# Loading both sensitive and non-sensitive dataset\n",
    "sen=loadDataset(\"SensitiveDataset.json\")\n",
    "nonsen=loadDataset(\"NonSensitiveDatasetnew.json\")\n",
    "\n",
    "import pandas as pd\n",
    "sen=pd.DataFrame(data=sen,columns=['sentences','labels'])\n",
    "nonsen=pd.DataFrame(data=nonsen,columns=['sentences','labels'])\n",
    "print(sen['labels'].value_counts(),nonsen['labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>username:aaliyah, password:123456, email:aaliy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>username:aaren, password:12345, email:aaren@ya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>username:aarika, password:123456789, email:aar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>username:aaron, password:iloveyou, email:aaron...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>username:aartjan, password:princess, email:aar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  labels\n",
       "0  username:aaliyah, password:123456, email:aaliy...       1\n",
       "1  username:aaren, password:12345, email:aaren@ya...       1\n",
       "2  username:aarika, password:123456789, email:aar...       1\n",
       "3  username:aaron, password:iloveyou, email:aaron...       1\n",
       "4  username:aartjan, password:princess, email:aar...       1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df1 and df2 are your two dataframes\n",
    "df= pd.concat([sen, nonsen], axis=0)  # Concatenate along rows (axis=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>username:deandre, password:dalejr, email:deand...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>full name:govinthan  govindammal, father's nam...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>username:chocs, password:smelly, email:chocs@l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ohio girl Marilyn Miller ends joining vaudevil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>full name:mahender  kumar, father's name:kumar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  labels\n",
       "0  username:deandre, password:dalejr, email:deand...       1\n",
       "1  full name:govinthan  govindammal, father's nam...       1\n",
       "2  username:chocs, password:smelly, email:chocs@l...       1\n",
       "3  Ohio girl Marilyn Miller ends joining vaudevil...       0\n",
       "4  full name:mahender  kumar, father's name:kumar...       1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15576, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sen=df[df['labels']==1]\n",
    "df_sen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non=df[df['labels']==0]\n",
    "df_non.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15576, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_non_downsampled = df_non.sample(df_sen.shape[0])\n",
    "df_non_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31152, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.concat([df_non_downsampled, df_sen])\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    15576\n",
       "1    15576\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20429    username:dena, password:bluesky, email:dena@ar...\n",
       "11507    After saving New York City demi-god Gozer, Gho...\n",
       "9000     full name:som  dutt, father's name:dutt, date ...\n",
       "9798     After bandit El Gavilan men blow South America...\n",
       "Name: sentences, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df_balanced['sentences'],df_balanced['labels'],stratify=df_balanced['labels'])\n",
    "X_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BERT-base pretrained model\n",
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get length of all the messages in the train set\n",
    "seq_len = [len(i.split()) for i in X_train]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of word index: 111939\n",
      "Saving the word index as JSON\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Size of word index:\", len(word_index))\n",
    "\n",
    "with open(\"word_index.json\", \"w\") as outfile:  \n",
    "    json.dump(word_index, outfile)\n",
    "    print(\"Saving the word index as JSON\")\n",
    "\n",
    "training_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_length, padding=padding_type, truncating=truncation_type)\n",
    "\n",
    "validation_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=truncation_type)\n",
    "\n",
    "#create attention masks for training and validation\n",
    "attention_masks = []\n",
    "for seq in training_padded:\n",
    "  seq_mask = [int(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask)\n",
    "\n",
    "attention_masks_val = []\n",
    "for seq in validation_padded:\n",
    "  seq_mask = [int(i>0) for i in seq]\n",
    "  attention_masks_val.append(seq_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = torch.tensor(training_padded.tolist())\n",
    "train_mask = torch.tensor(attention_masks)\n",
    "train_y = torch.tensor(y_train.tolist())\n",
    "\n",
    "test_seq = torch.tensor(validation_padded.tolist())\n",
    "test_mask = torch.tensor(attention_masks_val)\n",
    "test_y = torch.tensor(y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "#define a batch size\n",
    "batch_size = 32\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq,train_mask,train_y)\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(test_seq,test_mask,test_y)\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert):\n",
    "        super(BERT_Arch, self).__init__()      \n",
    "        self.bert = bert \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,2)\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    #define the forward pass\n",
    "    def forward(self, sent_id, mask):    \n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
    "        x = self.fc1(cls_hs)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a tensor model\n",
    "model = BERT_Arch(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# Move the model to the device\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1.0, 1.0]\n",
    "\n",
    "# converting list of class weights to a tensor\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "\n",
    "# push to GPU\n",
    "weights = weights.to(device)\n",
    "\n",
    "# define the loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "#defining epochs\n",
    "epochs = 1\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "#for each epoch\n",
    "for epoch in range(epochs):   \n",
    "    # function to train the model\n",
    "    def train():\n",
    "        model.train()\n",
    "        total_loss, total_accuracy = 0, 0\n",
    "        # empty list to save model predictions\n",
    "        total_preds=[]\n",
    "        # iterate over batches\n",
    "        for step,batch in enumerate(train_dataloader):\n",
    "            # progress update after every 50 batches.\n",
    "            if step % 50 == 0 and not step == 0:\n",
    "                print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "            # push the batch to gpu\n",
    "            batch = [torch.tensor(r).to(device) for r in batch]\n",
    "            sent_id, mask, labels = batch\n",
    "            # clear previously calculated gradients \n",
    "            model.zero_grad()        \n",
    "            # get model predictions for the current batch\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the loss between actual and predicted values\n",
    "            loss = cross_entropy(preds, labels)\n",
    "            # add on to the total loss\n",
    "            total_loss = total_loss + loss.item()\n",
    "            # backward pass to calculate the gradients\n",
    "            loss.backward()\n",
    "            # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            #defining optimizer\n",
    "            optimizer = torch.optim.AdamW(model.parameters(), lr = 1e-5)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "            # model predictions are stored on GPU. So, push it to CPU\n",
    "            preds=preds.detach().cpu().numpy()\n",
    "            # append the model predictions\n",
    "            total_preds.append(preds)\n",
    "        # compute the training loss of the epoch\n",
    "        avg_loss = total_loss / len(train_dataloader)\n",
    "        # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "        # reshape the predictions in form of (number of samples, no. of classes)\n",
    "        total_preds  = np.concatenate(total_preds, axis=0)\n",
    "        # returns the average loss and total predictions\n",
    "        return avg_loss, total_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():   \n",
    "    print(\"\\nEvaluating...\")\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(validation_padded):\n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            #elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "        # push the batch to gpu\n",
    "        batch = [torch.tensor(r).to(device) for r in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LAKSHMI SRI LASYA\\AppData\\Local\\Temp\\ipykernel_3080\\3441229909.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  batch = [torch.tensor(r).to(device) for r in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    50  of    731.\n",
      "  Batch   100  of    731.\n",
      "  Batch   150  of    731.\n",
      "  Batch   200  of    731.\n",
      "  Batch   250  of    731.\n",
      "  Batch   300  of    731.\n",
      "  Batch   350  of    731.\n",
      "  Batch   400  of    731.\n",
      "  Batch   450  of    731.\n",
      "  Batch   500  of    731.\n",
      "  Batch   550  of    731.\n",
      "  Batch   600  of    731.\n",
      "  Batch   650  of    731.\n",
      "  Batch   700  of    731.\n",
      "\n",
      "Training Loss: 0.334\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "#defining epochs\n",
    "epochs = 1\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    #train model\n",
    "    train_loss,_ = train()\n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "valid_losses=[]\n",
    "valid_loss,_ = evaluate()\n",
    "#save the best model\n",
    "if valid_loss < best_valid_loss:\n",
    "    best_valid_loss = valid_loss\n",
    "    torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "valid_losses.append(valid_loss)\n",
    "print(f'Validation Loss: {valid_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89      3894\n",
      "           1       0.90      0.86      0.88      3894\n",
      "\n",
      "    accuracy                           0.89      7788\n",
      "   macro avg       0.89      0.89      0.89      7788\n",
      "weighted avg       0.89      0.89      0.89      7788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
