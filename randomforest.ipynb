{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataList = []\n",
    "sentences = []\n",
    "labels = []\n",
    "# Stopwords should be removed or excluded from the given text so that more\n",
    "# focus can be given to those words which define the meaning of the text.\n",
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def loadDataset(filename):\n",
    "  d=[]\n",
    "  with open(filename, 'r') as f:\n",
    "      datastore = json.load(f)\n",
    "  for item in datastore:\n",
    "    sentence = item['data']\n",
    "    label = item['is_sensitive']\n",
    "    for word in stopwords: #Remove stop words in sentence\n",
    "      token = \" \" + word + \" \"\n",
    "      sentence = sentence.replace(token, \" \")\n",
    "    d.append([sentence,label])\n",
    "  return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sensitive and non-sensitive data from JSON files\n",
    "sen = loadDataset('SensitiveDataset.json')\n",
    "nonsen = loadDataset('NonSensitiveDatasetnew.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sen=pd.DataFrame(data=sen,columns=['sentences','labels'])\n",
    "nonsen=pd.DataFrame(data=nonsen,columns=['sentences','labels'])\n",
    "df= pd.concat([sen, nonsen], axis=0)\n",
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df_sen=df[df['labels']==1]\n",
    "df_non=df[df['labels']==0]\n",
    "df_non_downsampled = df_non.sample(15000)\n",
    "df_sen_downsampled=df_sen.sample(10000)\n",
    "df_balanced = pd.concat([df_non_downsampled, df_sen_downsampled])\n",
    "\n",
    "# Splitting into features (X) and labels (y)\n",
    "X = df_balanced['sentences'].values\n",
    "y = df_balanced['labels'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4502\n",
      "           1       1.00      1.00      1.00      2998\n",
      "\n",
      "    accuracy                           1.00      7500\n",
      "   macro avg       1.00      1.00      1.00      7500\n",
      "weighted avg       1.00      1.00      1.00      7500\n",
      "\n",
      "Accuracy:  0.9990666666666667\n"
     ]
    }
   ],
   "source": [
    "# Create a Random Forest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=1)\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predict the labels for the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      4502\n",
      "           1       0.98      0.98      0.98      2998\n",
      "\n",
      "    accuracy                           0.98      7500\n",
      "   macro avg       0.98      0.98      0.98      7500\n",
      "weighted avg       0.98      0.98      0.98      7500\n",
      "\n",
      "Accuracy:  0.984\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Create a Decision Tree classifier\n",
    "classifier = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=3)\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "# Predict the labels for the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Predictions: [0 1 0 0 0]\n",
      "Decision Tree Predictions: [0 1 0 0 0]\n",
      "Attribute Name is not sensitive (Random Forest)\n",
      "Attribute phone number is sensitive (Random Forest)\n",
      "Attribute email is not sensitive (Random Forest)\n",
      "Attribute address is not sensitive (Random Forest)\n",
      "Attribute occupation is not sensitive (Random Forest)\n",
      "Attribute Name is not sensitive (Decision Tree)\n",
      "Attribute phone number is sensitive (Decision Tree)\n",
      "Attribute email is not sensitive (Decision Tree)\n",
      "Attribute address is not sensitive (Decision Tree)\n",
      "Attribute occupation is not sensitive (Decision Tree)\n"
     ]
    }
   ],
   "source": [
    "# prompt: Now make user enter his attributes in a list and get seperate outputs for both above models and respective label for each attribute\n",
    "\n",
    "# Get user input for attributes\n",
    "attributes = input(\"Enter your attributes separated by commas: \").split(\",\")\n",
    "\n",
    "# Transform user input into a list of strings\n",
    "attributes_str = [str(attribute) for attribute in attributes]\n",
    "\n",
    "# Convert user input into a vectorized format\n",
    "attributes_vec = vectorizer.transform(attributes_str)\n",
    "\n",
    "# Predict the labels for the user input using Random Forest classifier\n",
    "rf_predictions = classifier.predict(attributes_vec)\n",
    "\n",
    "# Predict the labels for the user input using Decision Tree classifier\n",
    "dt_predictions = classifier.predict(attributes_vec)\n",
    "\n",
    "# Print the predictions for each model\n",
    "print(\"Random Forest Predictions:\", rf_predictions)\n",
    "print(\"Decision Tree Predictions:\", dt_predictions)\n",
    "\n",
    "# Print the label for each prediction\n",
    "for i in range(len(rf_predictions)):\n",
    "  if rf_predictions[i] == 1:\n",
    "    print(\"Attribute\", attributes[i], \"is sensitive (Random Forest)\")\n",
    "  else:\n",
    "    print(\"Attribute\", attributes[i], \"is not sensitive (Random Forest)\")\n",
    "\n",
    "for i in range(len(dt_predictions)):\n",
    "  if dt_predictions[i] == 1:\n",
    "    print(\"Attribute\", attributes[i], \"is sensitive (Decision Tree)\")\n",
    "  else:\n",
    "    print(\"Attribute\", attributes[i], \"is not sensitive (Decision Tree)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
